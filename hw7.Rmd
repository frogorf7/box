---
title: "HW7"
author: "Jinwoo Jeong"
date: '2022 4 27 '
output:
  pdf_document: default
  html_document: default
---

# Prob 2

a)
```{r}
library(e1071)
set.seed(4052)

x1 = runif(1000,0,1)-0.5
x2 = runif(1000,0,1)-0.5
x = c(x1,x2)

sep = x1-x2
y = rep(NA,1000)


for(i in 1:1000)
{
  if(sep[i]>0.1)
  {
    y[i] = 1
  }
  else if(sep[i]< -0.1)
  {
    y[i] = 0
  }
  else
  {
    y[i] = runif(1,0,1) > 0.5
  }
}

dat=data.frame(x1 = x1, x2 = x2, y = as.factor(y))
train=sample(1000, 500)
dat.train=dat[train, ]
dat.test=dat[-train, ]
par(mfrow = c(1,2))
plot(dat.train$x1, dat.train$x2, col = as.integer(dat.train$y) + 1, main = 'training set')
plot(dat.test$x1, dat.test$x2, col = as.integer(dat.test$y) + 1, main = 'test set')

```



b)


```{r}
set.seed(4052)
cost.grid=c(0.001, 0.01, 0.1, 1, 5, 10, 100, 10000)
tune.out=tune(svm, y ~., data = dat.train, kernel = 'linear', ranges = list(cost = cost.grid))
summary(tune.out)

for(cost in cost.grid)
{
svm.fit=svm(y ~ ., data = dat.train, kernel = "linear", cost = cost)
plot(svm.fit, data = dat.train)
}

print(data.frame(cost = tune.out$performance$cost, misclass = tune.out$performance$error * 1000))

```
```{r}
best_mod=tune.out$best.model
summary(best_mod)
```
among them 0.1 and 5 have the smallest midclassified training points

c)

```{r}
set.seed(4054)


err.rate.test=rep(NA, length(cost.grid))
for (cost in cost.grid) 
{
  svm.fit=svm(y ~ ., data = dat.train, kernel = 'linear', cost = cost)
  res=table(prediction = predict(svm.fit, newdata = dat.test), truth = dat.test$y)
  err.rate.test[match(cost, cost.grid)] <- (res[2,1] + res[1,2]) / sum(res)
}
err.rate.test

for (cost in cost.grid) 
{
  svm.fit=svm(y ~ ., data = dat.train, kernel = 'linear', cost = cost)
  ypred=predict(svm.fit, dat.test)
  tab = table(predict = ypred, truth = dat.test$y)
  print(paste(cost, ": cost "))
  print(paste(tab[1]+tab[4],"of the test observations are correctly classified" ))
}

```
best cost is 0.01 compare to the cost with training error 0.1 and 5 has slightly smaller compare to the others except 0.001, thus in here there are slight difference among test observations.

d)

With more cost we have slightly more correct test observations 
it may overfit the train data due to have more correct noisy point
smaller cost are perform better on the noisy test point but it may cause large margin.
overall the error rate is about 0.08


